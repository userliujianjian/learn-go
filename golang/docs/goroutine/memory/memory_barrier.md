## 内存屏障（TODO：未理解）

文本均在Linux（g++）下验证通过，CPU为x86-64处理器架构。
本文首先通过返利（以及内核代码）来解释Memory Barrier，然后介绍一个利用Memory Barrier实现的无锁环形缓冲区

#### 简介：
程序在运行时内存实际的访问顺序和程序代码编写的访问顺序不一定一致，这就是内存乱序访问。内存乱序访问行为出现的理由是为了提升程序运行时的性能。内存乱序访问主要发生在两个阶段：  
* 编译时，编译器优化导致内存乱序访问（指令重排）
* 运行时，多CPU间交互引起内存乱序访问  

memory Barrier能够让CPU或编译器在内存访问上有序。 一个Memory Barrier之前的内存访问操作必定先于其之后的完成。Memory Barrier包括两类： 
* 编译器Memory Barrier
* CPU Memory Barier
很多时候，编译器和CPU引起内存乱序访问不会带来什么问题，但一些特殊情况下，程序逻辑的正确性依赖于内存访问顺序，这时候内存乱序访问就会带来逻辑上的错误，例如：
```C++
// Thread 1
while(!ok);
do(x);

// Thread 2
x = 42;
ok = 1;

```
此段代码中，ok初始化为0，线程1嗯个爱ok被设置为1后执行do函数。假如说，线程2对内存的鞋操作乱序执行，也就是x赋值后与ok赋值完成，那么do函数接收的实参就很可能出乎程序员的医疗，不为42

#### **编译时内存乱序访问**。
在编译时，编译器对代码作出优化时可能改变实际执行指令的顺序（例如gcc下O2或O3都会改变实际执行指令的顺序）：  
```C++
// test.cpp

int x, y, r;
void f(){
	x = r;
	y = 1;
}

```

编译器优化的结果可能导致 y =1 在 x=r之前执行完成。首先直接编译此源文件：
g++ -S test.cpp

得到相关的汇编代码如下：
```C++
movl r(%rip), %eax
movl %eax, x(%rip)
movl $1, y(%rip)
```
着里我们看到，x=r和y=1并没有乱序。现在使用优化选项O2(或O3)在编译上面的代码(g++ -O2 -S test.cpp), 生成的汇编代码如下：
```c++
movl r(%rip), %eax
movl $1, y(%rip)
movl %eax, x(%rip)
```
我们可以清楚的看到经过编译器优化之后movl$1, y(%rip)先于movl %eax, x(%rip)执行。避免编译时内存乱序访问的办法就是使用编译器barrier(又叫优化barrier)。 Linux内核提供函数barrier()用于让编译器保证其之前的内存访问优先于其之后的完成。内核实现barrier()如下(x86-64架构)：
```C++
define barrier() __asm__ __volatitle__("":::"memory")
```

现在把此编译器barrier加入代码中：
```c++
int x, y, r;
void f()
{
x = r;
__asm__ __volatitle__("":::"memory")
y = 1;

}
```
这样就避免了编译器优化带来的内存乱序访问的问题了（如果有兴趣可以看看遍以后的汇编代码）。 本例中我们还可以使用volatitle这个关键字来避免编译时内存乱序访问（而无法避免后面要说的运行时内存乱序访问）。volatitle关键词能够让变量之间的内存访问上避免乱序，着里可以修改x和y的定义来解决问题：
```c++
volatitle int x, y;
int r;
void f()
{
	x = r;
	y = 1;
}
```
现在加上了volatitle关键字，这使得x相对于y、y相对于x在内存访问上有序。在Lunux内核中，提供了一个宏ACCESS_ONCE来避免编译器对连续的ACCESS_ONCE实例进行指令重排。起始ACCESS_ONCE实现远吗如下  
```c++
# define ACCESS_ONCE(x) (*(volatitle typeof(x) *)&(x))
```
此代码只是将变量x转换为volatitle的而已。现在我们就有第三个修改方案：  
```c++
int x, y, r;
void f()
{
ACCESS_ONCE(x) = r;
ACCESS_ONCE(y) = 1;
}
```
到此基本上就阐述完了我们编译时内存乱序访问的问题。下面开始介绍运行时内存乱序访问。

#### **运行时内存乱序访问**
在运行时，CPU虽然会乱序执行指令，但是在单个CPU上，硬件能够保证执行时所有的内存访问操作看起来像是按照程序代码编写的顺序执行的，这时候Memory Barrier没有必要使用（不考虑编译器优化的情况下）。这里我们了解一下CPU乱序执行的行为。在乱序执行时，一个处理器真正执行指令的顺序由可用的输入数据决定，而非程序员编写的顺序。  
早起的处理器为有序处理器(in-order processors), 有序处理器处理指令通常有以下几步：  
- 1. 指令获取
- 2. 如果指令的输入操作对象(input operands)可用（例如已经在寄存器中了），则将此指令分发到适当的功能单元中。如果一个或者多个操作对象不可用（通常是由于需要从内存中获取），则处理器会等待知道它们可用
- 3. 指令被适当的功能单元执行
- 4. 功能单元将结果协会寄存器堆(Register file, 一个cpu中的一组寄存器) 
相比之下，乱序处理器（out-of-order processors）处理指令通常需要以下几步：
- 1. 指令获取
- 2. 指令被分发到指令队列
- 3. 指令在指令队列中等待，知道输入操作对象可用（一旦输入操作对象可用，指令就可以离开队列，即便更早的指令为执行）
- 4. 指令被分配到适当的功能单元并执行
- 5. 执行结果被放入队列（而不立即写入寄存器堆）
- 6. 只有所有更早请求执行的指令的执行结果被写入寄存器堆后，指令执行的结果才被写入寄存器堆(执行结果冲排序，让执行看起来时有序的)  
从上面的执行过程可以看出，论序执行相比有序执行能够避免等待不可用的操作对象（有序执行的第二步）从而提高了效率。现代的机器上，处理器运行的速度比内存快很多，有序处理器花在等待可用数据的时间里已经可以处理大量指令了。  
<br>

现在思考一下乱序处理器处理指令的过程，我们能得到几个结论：
- 1. 对于单个CPU指令获取是有序的（通过队列实现）
- 2. 对于单个CPU指令执行结果也是有序返回寄存器堆的（通过队列实现）  
由此可知，在单CPU上，不考虑编译器优化导致乱序的前提下，多线程执行不存在内存乱序访问的问题。我们从内核源码也可以得到类似的结论(代码不完全摘录)： 
```c++
#ifdef CONFIG_SMP
#define smp_mb() mb()
#else
#define smp_mb() barrier()
#endif
```
这里可以看到，如果SMP则使用mb，mb被定义为CPU memory barrier（后面会讲到），而非SMP时，直接使用编译器barrier。  
在多CPU的机器上，问题有不一样了。每个CPU都存在cache（cache主要是为了弥补cpu和内存之间较慢的访问速度），当一个特定数据第一次被特定一个CPU获取时，此数据显然不在CPU的cache中（这就是cache miss）。此cache miss意味着CPU需要从内存中获取数据（这个过程需要CPU等待数百个周期），此数据将被加载到CPU的cache中,这样后续就能直接从cache上快速访问。当某个CPU进行写操作时，它必须确保其他的CPU已经将此数据从它们的cache中移除（以便保证一致性），只有在移除操作完成后此CPU才能安全的修改数据。显然，存在多个cache时，我们必须通过一个cache一致性协议来避免数据不一致的问题，而这个通讯的过程就可能导致乱序访问的出现，也就是这里说的运行时内存乱序访问。这里不再深入讨论细节，这是一个比较复杂的问题，有兴趣可以研究http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf 一文，其详细的分析了整个过程。

TODO：

#### 参考文章：
https://blog.csdn.net/caoshangpa/article/details/78853919








